{"initial_params": "[-0.00630073 -0.00409158  0.00483052 -0.00141986  0.00076781  0.0025742\n  0.00694738 -0.00711071 -0.0066859  -0.00788123  0.00612535  0.00333553\n -0.00017705 -0.00718676 -0.00649983  0.00102991 -0.00166135 -0.00125037\n -0.00315787  0.009342    0.00168375 -0.00872557 -0.00349431  0.00629693\n  0.00095098  0.00936359  0.00663325  0.00398426 -0.00462657 -0.00729584\n -0.00203473 -0.00432874 -0.00357044 -0.00962223 -0.00111818  0.00203983\n  0.00071895]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 37, "linear_w": 0.66, "X_train": "[0.14463737 0.26704715 0.21107864 0.7701702  0.13688856 0.76051387]", "Y_train": "[0.1687114  0.19925066 0.11962602 0.55329543 0.16481025 0.54911863]", "X_test": "[0.40924032 0.43434997 0.36060669 0.98617957 0.19409456 0.95544388\n 0.88275469 0.2121421  0.57756313 0.28242595 0.64272902 0.86971859\n 0.42953706 0.35442982 0.39867452 0.57917105 0.2930469  0.18738839\n 0.46098192 0.63963411]", "Y_test": "[0.40924032 0.43434997 0.36060669 0.98617957 0.19409456 0.95544388\n 0.88275469 0.2121421  0.57756313 0.28242595 0.64272902 0.86971859\n 0.42953706 0.35442982 0.39867452 0.57917105 0.2930469  0.18738839\n 0.46098192 0.63963411]"}