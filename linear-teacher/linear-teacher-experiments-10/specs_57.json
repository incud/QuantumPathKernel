{"initial_params": "[ 0.00278947  0.00592894 -0.00101362 -0.0014707   0.0082519  -0.00723196\n  0.00695812  0.00214223 -0.00460371  0.00722909 -0.00906319  0.00397944\n -0.00852196  0.00102729  0.00724924  0.00543141  0.00449772  0.00825391\n  0.00874654 -0.00877924  0.00744355 -0.0016456   0.00443352  0.00949287\n -0.0081557  -0.00117369 -0.00226175 -0.00295305 -0.00072979  0.00015916\n  0.00995691  0.0071102  -0.00869591  0.00414499  0.00732472  0.00920007\n  0.00405803 -0.00015396  0.00569292  0.00485975 -0.00508101 -0.00270126\n -0.00186198  0.00545519 -0.00797123  0.00307033 -0.00517701  0.00301323\n -0.00205166 -0.00503166  0.00785406  0.00938714  0.00962107  0.00401191\n -0.00714122 -0.00325545  0.00433328]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 57, "linear_w": 0.66, "X_train": "[0.23781329 0.35080598 0.19638873 0.48473166 0.4753448  0.71450002]", "Y_train": "[0.20492517 0.17234842 0.05031277 0.33085442 0.32976197 0.37437456]", "X_test": "[0.21260358 0.4129977  0.39310682 0.21258794 0.83918331 0.85834765\n 0.73586532 0.62077249 0.64275714 0.76672339 0.2658762  0.69553983\n 0.33426704 0.05240456 0.3132776  0.8250784  0.72605741 0.35964474\n 0.70329618 0.5314508 ]", "Y_test": "[0.14031836 0.27257848 0.2594505  0.14030804 0.55386098 0.56650945\n 0.48567111 0.40970984 0.42421971 0.50603744 0.17547829 0.45905629\n 0.22061625 0.03458701 0.20676322 0.54455174 0.47919789 0.23736553\n 0.46417548 0.35075753]"}