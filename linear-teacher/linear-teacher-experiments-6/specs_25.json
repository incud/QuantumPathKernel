{"initial_params": "[ 9.20604546e-03 -6.26752415e-03  8.17357405e-03  7.70533208e-05\n  2.37089734e-03 -8.39500123e-03 -8.51766170e-03 -8.41217730e-03\n -2.11196651e-03  7.93197897e-03  3.17354038e-03 -7.26070822e-03\n  6.21560203e-03 -3.40813047e-03  5.24954306e-03 -4.30150344e-03\n  7.10026851e-03 -5.45842549e-03 -2.60214922e-04 -8.57622818e-03\n -1.79669556e-05  2.84613021e-03  5.30615716e-03  9.54950724e-03\n  4.38862823e-04]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 25, "linear_w": 0.66, "X_train": "[0.17432317 0.99892449 0.59861876 0.7446086  0.84965676 0.06984615]", "Y_train": "[0.06811556 0.56993797 0.48313187 0.40372653 0.61367673 0.10292994]", "X_test": "[0.19712202 0.46515678 0.74171152 0.83687359 0.02820151 0.57914767\n 0.43692312 0.65637014 0.9769992  0.15062567 0.91199195 0.6586922\n 0.9680382  0.14053941 0.59106921 0.36351101 0.23088925 0.59437959\n 0.06469282 0.87884546]", "Y_test": "[0.13010053 0.30700347 0.4895296  0.55233657 0.018613   0.38223746\n 0.28836926 0.43320429 0.64481947 0.09941294 0.60191469 0.43473685\n 0.63890521 0.09275601 0.39010568 0.23991727 0.1523869  0.39229053\n 0.04269726 0.580038  ]"}