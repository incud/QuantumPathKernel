{"initial_params": "[ 0.00788749 -0.00427004 -0.00857566 -0.009231    0.00892205  0.00307822\n  0.00935755 -0.00149093  0.00025122  0.00276214 -0.0092211  -0.00920693\n -0.00405196  0.00762925  0.00202738 -0.00219694 -0.00557039 -0.00834722\n -0.00915865  0.00663378  0.00481784  0.00439508 -0.00655869  0.00154125\n -0.00613405 -0.00055481 -0.0057628  -0.00625322  0.00495516  0.00599908\n -0.00506435  0.00862643  0.00304022  0.00470709  0.00811686  0.00823693\n -0.00590501  0.00449589 -0.0026109   0.00669647 -0.00991303  0.00600126\n -0.00377119  0.00256617 -0.00460728  0.00114612 -0.00582596  0.00797238\n -0.00050848  0.00175433  0.00894317  0.00929172 -0.00242393 -0.00889455\n -0.00138233 -0.00089377  0.00708825]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 57, "linear_w": 0.66, "X_train": "[0.3002893  0.32456514 0.49594082 0.76632934 0.18276238 0.85991202]", "Y_train": "[0.13588001 0.2664784  0.34170477 0.58894768 0.03998402 0.5099215 ]", "X_test": "[0.18952991 0.74180689 0.89528743 0.02666569 0.37879955 0.91231765\n 0.03610475 0.57499417 0.30093758 0.43420013 0.39420244 0.28864213\n 0.78988327 0.83015368 0.38541857 0.94490628 0.24381442 0.82962356\n 0.40416744 0.44500707]", "Y_test": "[0.12508974 0.48959255 0.5908897  0.01759936 0.2500077  0.60212965\n 0.02382914 0.37949615 0.1986188  0.28657209 0.26017361 0.19050381\n 0.52132296 0.54790143 0.25437626 0.62363814 0.16091752 0.54755155\n 0.26675051 0.29370467]"}