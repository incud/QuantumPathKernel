{"initial_params": "[-0.00139278  0.0079331   0.00334292 -0.00777451 -0.00508257  0.00975404\n  0.00872595  0.00028764  0.00157883 -0.00813015  0.00383456  0.00720593\n  0.00838895  0.00099364 -0.00450349  0.00674641 -0.00721544  0.00849456\n -0.00652248  0.00945473  0.00588144  0.00277664 -0.00072303  0.00387878\n  0.00219376  0.00290219 -0.0039087  -0.00949843 -0.00802824 -0.00017508\n -0.00064488  0.00261337 -0.00560355 -0.00722649  0.00629614 -0.00801225\n -0.00535825  0.00376535  0.00053727]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 39, "linear_w": 0.66, "X_train": "[0.27719241 0.03970685 0.45842884 0.41721544 0.17995415 0.60573264]", "Y_train": "[0.11748067 0.09329376 0.27864345 0.30046941 0.17674315 0.43517483]", "X_test": "[0.18834703 0.6440934  0.49198589 0.10802364 0.1119414  0.60104066\n 0.53135394 0.23583496 0.85493794 0.51567941 0.06546984 0.37391226\n 0.780945   0.64302156 0.45718205 0.82863687 0.13631781 0.38855742\n 0.68720252 0.71386132]", "Y_test": "[0.12430904 0.42510164 0.32471069 0.0712956  0.07388132 0.39668684\n 0.3506936  0.15565107 0.56425904 0.34034841 0.04321009 0.24678209\n 0.5154237  0.42439423 0.30174015 0.54690033 0.08996975 0.2564479\n 0.45355366 0.47114847]"}