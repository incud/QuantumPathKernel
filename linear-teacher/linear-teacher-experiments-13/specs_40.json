{"initial_params": "[-0.00468684  0.00209537 -0.00532442 -0.00063249 -0.00707763 -0.00139429\n -0.00365448 -0.00102457 -0.00323968  0.00376559  0.00018931 -0.00551406\n -0.00500626  0.00552581 -0.00171391  0.00861631  0.00945743  0.00345043\n -0.00826181  0.00392219  0.00052703  0.00924523 -0.00590134 -0.00629602\n  0.00848414  0.00977721  0.00202831  0.00930413  0.00489752  0.00075769\n -0.00199634  0.00092475  0.00272857  0.00027078 -0.00269304  0.00517098\n  0.00301093 -0.0014592   0.00386974 -0.0037653 ]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 40, "linear_w": 0.66, "X_train": "[0.76458198 0.85915787 0.42662    0.69325588 0.49472381 0.0058524 ]", "Y_train": "[ 0.4385501   0.51443799  0.3156513   0.4760616   0.32682998 -0.0945965 ]", "X_test": "[0.45661456 0.3181137  0.56072842 0.28274236 0.30407772 0.9875151\n 0.21772916 0.88302092 0.52457253 0.78226492 0.21517031 0.764323\n 0.63547353 0.86385229 0.39501203 0.04520522 0.08384501 0.92799543\n 0.88116601 0.75206137]", "Y_test": "[0.30136561 0.20995504 0.37008076 0.18660996 0.2006913  0.65175997\n 0.14370125 0.58279381 0.34621787 0.51629485 0.1420124  0.50445318\n 0.41941253 0.57014251 0.26070794 0.02983545 0.05533771 0.61247698\n 0.58156957 0.4963605 ]"}