{"initial_params": "[ 2.03391325e-03 -2.16194862e-03 -8.18871891e-03  2.02817122e-03\n -9.87178897e-03  2.88270592e-03 -6.08656261e-03 -9.91243637e-03\n  1.90164800e-03 -4.48391272e-03  1.63294999e-03  7.94638130e-04\n -9.16613289e-03  9.92838025e-05 -9.31265206e-03  1.72871443e-03\n  3.82218642e-03  4.90456428e-03  2.30429907e-03 -3.30706224e-03\n -9.45669803e-03 -9.34629458e-03 -6.11173075e-03 -4.64953575e-04\n -4.78414486e-03  9.17713979e-03]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 26, "linear_w": 0.66, "X_train": "[0.30239767 0.89569399 0.68453884 0.70174566 0.06570498 0.87241911]", "Y_train": "[0.12596722 0.54743598 0.38186224 0.51938176 0.05141109 0.56185246]", "X_test": "[0.48288189 0.60304638 0.66915227 0.45008848 0.504314   0.980355\n 0.07051453 0.12816087 0.57458868 0.75302909 0.73887169 0.16640967\n 0.72100167 0.56788029 0.97330682 0.15505728 0.36027898 0.33272556\n 0.72061095 0.18094388]", "Y_test": "[0.31870205 0.39801061 0.4416405  0.2970584  0.33284724 0.6470343\n 0.04653959 0.08458617 0.37922853 0.4969992  0.48765532 0.10983038\n 0.4758611  0.37480099 0.6423825  0.1023378  0.23778413 0.21959887\n 0.47560323 0.11942296]"}