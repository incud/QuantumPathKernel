{"initial_params": "[ 0.00480116 -0.00013427  0.00075372 -0.00248616  0.00919609 -0.00745878\n -0.00168794  0.00572596  0.00348079  0.00532094 -0.0069805   0.00299403\n  0.00464113  0.00041921 -0.0084693   0.00075319  0.00373981 -0.00284692\n -0.00399168  0.00969633  0.00521556  0.00317325 -0.00304509 -0.00680363\n -0.0072132  -0.00748601  0.00477207  0.00829929  0.00820045  0.00435812\n  0.00792847 -0.0065571   0.00722043 -0.00701709  0.00602014 -0.00661887\n  0.00878031  0.00138086  0.00587992  0.00280928  0.00081902  0.0018617\n -0.00595303  0.00155451  0.00497528 -0.00842111 -0.00691482 -0.00839869\n  0.00745172 -0.00790706 -0.00541777 -0.00106508 -0.00731632  0.00609059\n -0.0007486   0.0029839  -0.00660489 -0.00258115  0.00197257  0.00421822]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 60, "linear_w": 0.66, "X_train": "[0.15450343 0.32849825 0.01905854 0.13121882 0.54916708 0.13688322]", "Y_train": "[0.01274226 0.243088   0.08716685 0.16839268 0.45555544 0.05351334]", "X_test": "[0.07595384 0.69446646 0.37999089 0.89028652 0.14677678 0.02645904\n 0.29889047 0.19621023 0.99897478 0.41611912 0.37017485 0.24625981\n 0.62562883 0.04648472 0.08817255 0.48093445 0.12206774 0.47142138\n 0.27352867 0.52538459]", "Y_test": "[0.07595384 0.69446646 0.37999089 0.89028652 0.14677678 0.02645904\n 0.29889047 0.19621023 0.99897478 0.41611912 0.37017485 0.24625981\n 0.62562883 0.04648472 0.08817255 0.48093445 0.12206774 0.47142138\n 0.27352867 0.52538459]"}