{"initial_params": "[ 0.00729409 -0.00024138 -0.00548365 -0.00479404  0.00395295 -0.00671824\n  0.00068126 -0.00652476 -0.00818785 -0.00675107  0.00996058  0.00307329\n -0.00736481  0.00638534 -0.00421707 -0.00616755 -0.0096139  -0.00789735\n  0.00467528  0.0081291   0.0022284   0.00311533  0.00375405  0.00857959\n -0.00553651 -0.00362524 -0.00886438 -0.00198117  0.00501937 -0.00980005\n -0.00599614  0.00931882 -0.00035288 -0.00638431 -0.00265131 -0.00248981\n -0.00726053  0.00915248  0.00703139 -0.00162191  0.00274229 -0.00731468\n -0.00695039 -0.00241599  0.00491293 -0.00388018  0.00611514  0.00408661\n -0.00471531 -0.00326992  0.00653209  0.0089748   0.0077012 ]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 53, "linear_w": 0.66, "X_train": "[0.03978755 0.75375794 0.0664911  0.51570816 0.92255148 0.8465896 ]", "Y_train": "[ 0.07924263  0.52242828 -0.03500192  0.36190989  0.55636551  0.6450432 ]", "X_test": "[0.80579998 0.79003007 0.19058577 0.3015616  0.3008538  0.50283891\n 0.25573646 0.08027719 0.49969938 0.28811479 0.36160409 0.17127868\n 0.37675057 0.87773373 0.77181618 0.3461801  0.64263125 0.28417974\n 0.53598494 0.81091207]", "Y_test": "[0.80579998 0.79003007 0.19058577 0.3015616  0.3008538  0.50283891\n 0.25573646 0.08027719 0.49969938 0.28811479 0.36160409 0.17127868\n 0.37675057 0.87773373 0.77181618 0.3461801  0.64263125 0.28417974\n 0.53598494 0.81091207]"}