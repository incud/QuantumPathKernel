{"initial_params": "[ 0.0066776  -0.00495723  0.0060775  -0.00676564  0.00796868  0.00252616\n  0.00779859  0.00133962  0.00835475  0.00495077 -0.00598576  0.00935991\n  0.00238026  0.00183617 -0.00664525  0.00702672 -0.00408333  0.00449551\n -0.00659014 -0.00585732 -0.0022591  -0.00067461  0.00033813  0.00898056\n -0.00869891 -0.00449387 -0.00067077 -0.00831695  0.00091118 -0.00716848\n -0.00285302  0.00364428 -0.00855423 -0.00853272  0.00511203 -0.00301811\n -0.00875597 -0.00616152]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 38, "linear_w": 0.66, "X_train": "[0.96111884 0.75153024 0.36852396 0.01389487 0.5775713  0.5242851 ]", "Y_train": "[0.7187453  0.57698941 0.31806898 0.03350694 0.46241062 0.44422966]", "X_test": "[0.54591647 0.21415861 0.90368451 0.29054151 0.24065081 0.00657707\n 0.89250923 0.12682384 0.56178278 0.06791361 0.92573819 0.62511464\n 0.85480576 0.91134328 0.69579592 0.78644058 0.8026753  0.68124691\n 0.81108793 0.39745427]", "Y_test": "[0.54591647 0.21415861 0.90368451 0.29054151 0.24065081 0.00657707\n 0.89250923 0.12682384 0.56178278 0.06791361 0.92573819 0.62511464\n 0.85480576 0.91134328 0.69579592 0.78644058 0.8026753  0.68124691\n 0.81108793 0.39745427]"}