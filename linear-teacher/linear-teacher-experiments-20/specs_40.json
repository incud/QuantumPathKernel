{"initial_params": "[-0.00079675  0.00152571  0.00668095  0.00762167 -0.0016146  -0.00574888\n -0.00328232 -0.00277258 -0.00258421 -0.00363466  0.00301453  0.00757675\n  0.00024295 -0.00490399 -0.00651025  0.00772095 -0.00284698  0.00700348\n -0.00395203 -0.00076333 -0.00906212  0.00769075  0.00033503  0.00610692\n  0.00203688  0.00805289 -0.00675955 -0.00777968 -0.00754392 -0.00799381\n  0.00364632 -0.00753234 -0.00290157 -0.00663366  0.00694786 -0.00863019\n -0.00650618 -0.00061806 -0.00155703  0.00824734]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 40, "linear_w": 0.66, "X_train": "[0.51432352 0.3364997  0.63571151 0.49944908 0.08966362 0.31343388]", "Y_train": "[0.34022885 0.18153441 0.49659847 0.3381822  0.11093777 0.1334382 ]", "X_test": "[0.98447024 0.24074484 0.13142142 0.47424323 0.11740777 0.02882646\n 0.65224229 0.94743153 0.61972561 0.28016425 0.61833991 0.84760281\n 0.23575582 0.15728026 0.92448751 0.29878271 0.34465432 0.6132738\n 0.12058463 0.28969869]", "Y_test": "[0.98447024 0.24074484 0.13142142 0.47424323 0.11740777 0.02882646\n 0.65224229 0.94743153 0.61972561 0.28016425 0.61833991 0.84760281\n 0.23575582 0.15728026 0.92448751 0.29878271 0.34465432 0.6132738\n 0.12058463 0.28969869]"}