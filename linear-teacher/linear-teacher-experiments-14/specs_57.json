{"initial_params": "[ 0.00432851 -0.00099197 -0.00488861 -0.00677467  0.00359008 -0.00392423\n -0.00998215  0.00785528  0.00974848  0.0070841   0.0031306  -0.00214376\n  0.00886043 -0.00860167 -0.00459798 -0.00502198  0.00945842  0.00542308\n  0.00084873 -0.0025624  -0.00894178  0.00648679  0.0062704   0.0053875\n -0.00376093 -0.00299062  0.00826116  0.00777089 -0.00010403 -0.00590115\n -0.00065605  0.00780272  0.0060524   0.0032408   0.00063192  0.00253028\n -0.00972374 -0.00532437 -0.00875276  0.00403062  0.0035157   0.00848365\n -0.00298772 -0.00859793  0.00474252  0.00258345 -0.00667669  0.00460636\n  0.00055995 -0.00268607 -0.00685923 -0.00743431  0.00990612 -0.00603577\n  0.00909285 -0.007181   -0.00326631]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 57, "linear_w": 0.66, "X_train": "[0.51942741 0.62402721 0.64923728 0.14216069 0.61355201 0.32619428]", "Y_train": "[0.34855275 0.46108989 0.52414968 0.19212162 0.36903361 0.26430031]", "X_test": "[0.38263936 0.28983828 0.51000776 0.97021953 0.57255128 0.64712339\n 0.54759227 0.6570048  0.34562162 0.03663097 0.72431313 0.96490891\n 0.78297398 0.53851726 0.70054349 0.36767027 0.28001365 0.98974404\n 0.41041063 0.43610033]", "Y_test": "[0.38263936 0.28983828 0.51000776 0.97021953 0.57255128 0.64712339\n 0.54759227 0.6570048  0.34562162 0.03663097 0.72431313 0.96490891\n 0.78297398 0.53851726 0.70054349 0.36767027 0.28001365 0.98974404\n 0.41041063 0.43610033]"}