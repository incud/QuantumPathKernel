{"initial_params": "[-0.00117229  0.0036522   0.00494811  0.00842027 -0.00277235 -0.00215531\n  0.00315505 -0.00770372 -0.00436832 -0.00365406  0.00764182  0.00943738\n -0.00118689  0.00094906 -0.00998407 -0.00309117 -0.00593025 -0.00912108\n  0.00204362 -0.00749609  0.00699323  0.00591476 -0.0020233  -0.0051071\n -0.00226856  0.00019544 -0.00457958 -0.00961138 -0.0086826   0.00671182\n -0.00872497  0.00199045 -0.00486616  0.00121488  0.00072048  0.00188899\n -0.00295643 -0.00929202  0.00551645  0.00589342  0.00611936  0.00327454\n -0.00353221 -0.00402927 -0.00670467 -0.00254992 -0.00595173 -0.00580598\n  0.00368701  0.00163702  0.00157372  0.00574477  0.0099556  -0.00695417]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 54, "linear_w": 0.66, "X_train": "[0.87843631 0.52918763 0.54009433 0.76708478 0.30644218 0.55175943]", "Y_train": "[0.59717513 0.25572783 0.39745046 0.58798018 0.13501548 0.30963845]", "X_test": "[0.01879639 0.99480756 0.07287269 0.10318038 0.37683731 0.8960233\n 0.97511499 0.01639266 0.2692798  0.11010934 0.98500853 0.37122564\n 0.30195916 0.80761525 0.98328299 0.49497364 0.65471407 0.79961714\n 0.93867738 0.36960456]", "Y_test": "[0.01879639 0.99480756 0.07287269 0.10318038 0.37683731 0.8960233\n 0.97511499 0.01639266 0.2692798  0.11010934 0.98500853 0.37122564\n 0.30195916 0.80761525 0.98328299 0.49497364 0.65471407 0.79961714\n 0.93867738 0.36960456]"}