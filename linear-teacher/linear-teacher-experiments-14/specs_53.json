{"initial_params": "[-0.00112218 -0.00328172 -0.00771144 -0.00996545 -0.00326396  0.00468593\n -0.00061127  0.00243236  0.00693171 -0.00068948 -0.00323285 -0.00526225\n -0.0030486  -0.00569105 -0.00817406  0.00668374 -0.00245393  0.00056804\n -0.00764425 -0.00432589 -0.00204946 -0.00449094  0.00287241 -0.00430477\n -0.00149758  0.00882136  0.00208205  0.00553587  0.00585886 -0.00490452\n  0.00595943  0.00107129  0.00317169 -0.0004017  -0.00082983  0.00817197\n -0.0024774  -0.00575599  0.00911776  0.0031829   0.00306398 -0.00646681\n  0.00502016  0.00039312  0.00117503  0.00140805  0.00412194 -0.00348833\n -0.00388899 -0.00280383  0.00076468  0.00134483 -0.00937181]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 53, "linear_w": 0.66, "X_train": "[0.75397265 0.30952425 0.6893279  0.70307979 0.27611237 0.64347045]", "Y_train": "[0.46123596 0.1525521  0.49129564 0.49732715 0.09590707 0.3573306 ]", "X_test": "[0.97690566 0.42996491 0.8638376  0.66614242 0.06876644 0.76176276\n 0.76542291 0.87202623 0.20485754 0.31574564 0.361057   0.95383119\n 0.19869101 0.14985534 0.7970189  0.3502628  0.66346559 0.08766252\n 0.75233866 0.48608646]", "Y_test": "[0.64475774 0.28377684 0.57013282 0.439654   0.04538585 0.50276342\n 0.50517912 0.57553731 0.13520598 0.20839212 0.23829762 0.62952859\n 0.13113607 0.09890452 0.52603247 0.23117345 0.43788729 0.05785726\n 0.49654352 0.32081706]"}