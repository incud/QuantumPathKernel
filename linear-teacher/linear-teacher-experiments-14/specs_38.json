{"initial_params": "[-0.00488309 -0.00621643 -0.0013184   0.0087976   0.00026637 -0.0061711\n -0.0002063  -0.00056218  0.00031342  0.0090059  -0.00194361 -0.00781066\n  0.00155288  0.00218391 -0.00315065  0.00416814 -0.00290618 -0.00821408\n  0.0099088  -0.00282141  0.00680445  0.00885202  0.00293107 -0.00807506\n -0.0051919  -0.0056351   0.00473872 -0.00408148 -0.00618426  0.00785385\n -0.00782559 -0.00399464  0.004753   -0.00944908 -0.00932973  0.00259665\n -0.00843857 -0.00023438]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 38, "linear_w": 0.66, "X_train": "[0.71449562 0.7567477  0.89078146 0.44893812 0.6114793  0.28464149]", "Y_train": "[0.40961968 0.4269555  0.63218396 0.35545042 0.32826363 0.2060754 ]", "X_test": "[0.63573375 0.24621624 0.87997332 0.76843549 0.49765253 0.96729766\n 0.18109331 0.5150525  0.25590046 0.5195248  0.55363244 0.83671991\n 0.51795168 0.85273378 0.32047475 0.62063523 0.27894849 0.85732217\n 0.40559477 0.11973209]", "Y_test": "[0.63573375 0.24621624 0.87997332 0.76843549 0.49765253 0.96729766\n 0.18109331 0.5150525  0.25590046 0.5195248  0.55363244 0.83671991\n 0.51795168 0.85273378 0.32047475 0.62063523 0.27894849 0.85732217\n 0.40559477 0.11973209]"}