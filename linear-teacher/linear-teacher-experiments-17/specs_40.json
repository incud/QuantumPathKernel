{"initial_params": "[-0.00685965 -0.00036605 -0.00881137  0.00512203 -0.0022104   0.0069263\n  0.00120309  0.00040094 -0.00739    -0.00973075 -0.00229945 -0.00475929\n  0.00632787 -0.00399913 -0.0001008  -0.00493748 -0.00620653 -0.00974681\n  0.00201746  0.00560757 -0.00874602 -0.00119825 -0.0017451  -0.00845872\n  0.00316863  0.00288896  0.00403824  0.00270897  0.00681679 -0.00160103\n -0.00193059  0.00855666 -0.00675564  0.00458324  0.00037659 -0.00648681\n -0.00436535 -0.00726182 -0.0043896   0.00592315]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 40, "linear_w": 0.66, "X_train": "[0.90295248 0.43506221 0.69334668 0.59758794 0.47356807 0.33238507]", "Y_train": "[0.61038365 0.33476005 0.50558753 0.45944258 0.29918818 0.12623551]", "X_test": "[0.5766664  0.42701879 0.94059032 0.60916328 0.2175893  0.32122702\n 0.42465017 0.83531641 0.90233068 0.9639099  0.10532109 0.34274087\n 0.84942796 0.92445609 0.20682487 0.43537502 0.51550854 0.3164894\n 0.13246981 0.38589002]", "Y_test": "[0.38059982 0.2818324  0.62078961 0.40204776 0.14360894 0.21200983\n 0.28026911 0.55130883 0.59553825 0.63618053 0.06951192 0.22620897\n 0.56062245 0.61014102 0.13650441 0.28734751 0.34023564 0.208883\n 0.08743007 0.25468741]"}