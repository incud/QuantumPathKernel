{"initial_params": "[-0.00275128 -0.00917502  0.0079629  -0.00924388 -0.00033315 -0.00377615\n  0.00801469 -0.00521308 -0.00870456  0.00384563 -0.00664958  0.00998958\n -0.00573765 -0.00657992 -0.00162676  0.00837267  0.00237283  0.00704333\n -0.00975692  0.00827288 -0.0099533   0.00503493  0.00264372 -0.00620156\n  0.00211874 -0.00405042 -0.00296983  0.00880875 -0.0081719   0.00621886\n -0.00349717 -0.0077109  -0.00726847  0.00631037 -0.00464663 -0.00805838\n  0.0021848  -0.00625046 -0.00476128  0.00374959  0.00317753  0.00147126]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 42, "linear_w": 0.66, "X_train": "[0.73722457 0.92021431 0.00147375 0.84395039 0.43430081 0.17072289]", "Y_train": "[ 0.43900805  0.6849781  -0.01241108  0.46695665  0.2128495   0.14099814]", "X_test": "[0.2773374  0.78426328 0.52626895 0.65080618 0.35656958 0.46892115\n 0.09621104 0.81761629 0.86084582 0.8461128  0.19889021 0.01278334\n 0.26925434 0.63547461 0.32795148 0.40418706 0.99594286 0.27669369\n 0.84917359 0.27315286]", "Y_test": "[0.18304268 0.51761376 0.34733751 0.42953208 0.23533592 0.30948796\n 0.06349929 0.53962675 0.56815824 0.55843445 0.13126754 0.008437\n 0.17770786 0.41941324 0.21644798 0.26676346 0.65732229 0.18261784\n 0.56045457 0.18028089]"}