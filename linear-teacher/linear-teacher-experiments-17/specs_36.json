{"initial_params": "[-0.00692759 -0.00235478 -0.00052601  0.00663413 -0.00516874  0.00086259\n -0.00419687  0.00944044 -0.00619322  0.00301752  0.00382987 -0.00041561\n  0.00461166 -0.00830399 -0.00091518 -0.00280548 -0.00742091 -0.00815475\n -0.00964683 -0.00382249  0.0052869   0.00661844  0.00522272 -0.00680041\n -0.00860209  0.00631485 -0.0016504   0.0014484  -0.00704819 -0.00508673\n  0.00576336  0.00487667 -0.00568149  0.00601406  0.00182895  0.00414051]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 36, "linear_w": 0.66, "X_train": "[0.06796373 0.72807014 0.42108093 0.0757766  0.87565442 0.90079589]", "Y_train": "[ 0.12345462  0.3942677   0.20642506 -0.04000275  0.65617079  0.52087016]", "X_test": "[0.73370217 0.78969184 0.80077997 0.99555679 0.78323535 0.97771834\n 0.0416412  0.83594022 0.31057876 0.8744011  0.32132725 0.60323088\n 0.86290825 0.99185785 0.31679581 0.91555009 0.99900024 0.16313947\n 0.73043925 0.07428309]", "Y_test": "[0.48424343 0.52119661 0.52851478 0.65706748 0.51693533 0.6452941\n 0.02748319 0.55172055 0.20498198 0.57710473 0.21207599 0.39813238\n 0.56951945 0.65462618 0.20908523 0.60426306 0.65934016 0.10767205\n 0.4820899  0.04902684]"}