{"initial_params": "[-0.00059459  0.00858207 -0.00681165 -0.00196331  0.00539788 -0.00467397\n -0.00796529  0.00378306  0.00787136 -0.00897217 -0.00084839 -0.0019467\n -0.00392792  0.00899195 -0.00712549  0.00364632 -0.00580541 -0.00706032\n  0.0007135  -0.00215997 -0.00073273  0.00824694  0.0089606   0.00247313\n  0.0031455   0.00218714 -0.00748792 -0.00813204 -0.00807482 -0.00598696\n -0.0064524   0.00147819  0.00902769  0.00085779 -0.00989745  0.00060851\n  0.00809739 -0.00454885  0.00392251 -0.00930698  0.00352116 -0.00544074\n  0.00772332 -0.00981379 -0.00630764  0.00880603  0.00131515  0.00904164\n -0.00447738 -0.00578822  0.00511192 -0.00771346  0.00998879  0.00419108\n  0.00343992  0.00132343 -0.00564917  0.00938445 -0.0032364 ]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 59, "linear_w": 0.66, "X_train": "[0.71264564 0.72537339 0.28607776 0.53365028 0.04514889 0.75505408]", "Y_train": "[0.43400427 0.41972278 0.2632457  0.34211567 0.12110392 0.39844915]", "X_test": "[0.65179713 0.03537311 0.11040879 0.60681314 0.85628936 0.09251449\n 0.35707425 0.9761762  0.23731867 0.73872149 0.04624097 0.14839975\n 0.60011812 0.38531175 0.32103821 0.44594295 0.16912966 0.94200165\n 0.3049249  0.01836133]", "Y_test": "[0.43018611 0.02334625 0.0728698  0.40049667 0.56515098 0.06105956\n 0.235669   0.64427629 0.15663032 0.48755618 0.03051904 0.09794384\n 0.39607796 0.25430576 0.21188522 0.29432235 0.11162558 0.62172109\n 0.20125043 0.01211848]"}