{"initial_params": "[ 0.00012708  0.00577979  0.0035139   0.00299243 -0.00463906  0.00247589\n -0.00079957  0.00203753 -0.00366972 -0.0049426   0.00010548 -0.00575474\n -0.00699904  0.00151723  0.00460191 -0.00517278  0.00959604 -0.00945891\n -0.00030576  0.00428568  0.00603947 -0.00780679 -0.00221471  0.00564401\n  0.00170668 -0.00508287 -0.0085902  -0.00671311 -0.00267383  0.0016798\n  0.0025043   0.00030641  0.00829803 -0.00516822  0.00419119 -0.00976127\n -0.00373561  0.00554612  0.00433683  0.00857441  0.00824298 -0.00285485\n -0.00862091 -0.00450976  0.00084822  0.00450856 -0.00368187 -0.00957598\n  0.00486392  0.00228065  0.00375738 -0.00761685 -0.00624458 -0.00474615\n  0.00106606 -0.00517055 -0.00707628  0.00022553]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 58, "linear_w": 0.66, "X_train": "[0.59909874 0.41033591 0.72390963 0.29104591 0.20251461 0.69997345]", "Y_train": "[0.4833285  0.3607331  0.39464808 0.20504766 0.05665221 0.45584529]", "X_test": "[0.82501621 0.96639573 0.908046   0.37685604 0.26702262 0.2076537\n 0.11326883 0.21225651 0.22414513 0.36703434 0.68220492 0.28789532\n 0.0731656  0.09231225 0.91593079 0.7544932  0.61898436 0.58855407\n 0.00461283 0.38204838]", "Y_test": "[0.82501621 0.96639573 0.908046   0.37685604 0.26702262 0.2076537\n 0.11326883 0.21225651 0.22414513 0.36703434 0.68220492 0.28789532\n 0.0731656  0.09231225 0.91593079 0.7544932  0.61898436 0.58855407\n 0.00461283 0.38204838]"}