{"initial_params": "[-0.00729566 -0.00579707 -0.00808909  0.00163214 -0.00922901 -0.00987966\n  0.00644314  0.00584827  0.00796066  0.00015582  0.00300044 -0.00808901\n  0.00860445  0.00334611 -0.00818368 -0.00071227  0.00233629 -0.00857799\n -0.00882862  0.00818195  0.00435798  0.00399499  0.00097868  0.00660175\n  0.00013445  0.0041093   0.00467486 -0.00187014 -0.00204313  0.00704697\n  0.00176533  0.00741069 -0.00943994  0.00669797 -0.00540891  0.00678088\n -0.00105835  0.00936692  0.00346248  0.00242049]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 40, "linear_w": 0.66, "X_train": "[0.74204677 0.41596803 0.77306068 0.80302818 0.1104548  0.02209798]", "Y_train": "[0.41202598 0.22540164 0.5004319  0.5280305  0.01252309 0.04885797]", "X_test": "[0.86494676 0.14358915 0.73039093 0.2323767  0.74279805 0.53450495\n 0.50410399 0.44390623 0.6891571  0.45992423 0.5449311  0.29520217\n 0.64752399 0.81388976 0.19822859 0.44468217 0.94911732 0.99002698\n 0.00873341 0.95545406]", "Y_test": "[0.57086486 0.09476884 0.48205801 0.15336862 0.49024671 0.35277327\n 0.33270863 0.29297811 0.45484369 0.30354999 0.35965453 0.19483343\n 0.42736583 0.53716724 0.13083087 0.29349023 0.62641743 0.65341781\n 0.00576405 0.63059968]"}