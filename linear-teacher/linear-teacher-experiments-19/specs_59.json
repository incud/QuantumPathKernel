{"initial_params": "[ 0.00502347 -0.00236403  0.00990531  0.00447522 -0.00502219  0.00593034\n  0.00265606 -0.00312949  0.00795803  0.00638406 -0.00763901 -0.00972785\n -0.00116445  0.00995824  0.0003971  -0.00585532  0.00419796  0.00323853\n  0.00294924  0.00237085 -0.00177743 -0.00082948 -0.00714002  0.00313148\n  0.0042065  -0.00982175 -0.00350964 -0.00218017  0.00608825  0.00527725\n -0.00901371  0.00608823  0.0014742   0.00842949 -0.00194902  0.00472126\n  0.00151068  0.00611695  0.00423498  0.00561445 -0.00941061 -0.0069614\n -0.00968533 -0.00435291  0.00226879 -0.00879113 -0.00164659 -0.00937322\n  0.0065712   0.00775446  0.00391332  0.00021127 -0.00566061 -0.00115929\n -0.0059218   0.00509907  0.00927047  0.00696848 -0.00557583]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 59, "linear_w": 0.66, "X_train": "[0.02517468 0.6342109  0.25467301 0.98192074 0.60519632 0.90380441]", "Y_train": "[0.02715033 0.38239064 0.11408642 0.55003877 0.37077482 0.6608436 ]", "X_test": "[0.37825946 0.98565507 0.78187258 0.9234373  0.28714541 0.10812747\n 0.1056938  0.59163935 0.04697727 0.43383663 0.80190633 0.3502836\n 0.35306574 0.59880099 0.5238484  0.37367547 0.94070348 0.83035005\n 0.65687866 0.76663827]", "Y_test": "[0.37825946 0.98565507 0.78187258 0.9234373  0.28714541 0.10812747\n 0.1056938  0.59163935 0.04697727 0.43383663 0.80190633 0.3502836\n 0.35306574 0.59880099 0.5238484  0.37367547 0.94070348 0.83035005\n 0.65687866 0.76663827]"}