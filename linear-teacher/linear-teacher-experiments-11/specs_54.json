{"initial_params": "[-0.00583566  0.00733548  0.00853109  0.00439208 -0.00452705 -0.00420666\n -0.00483827 -0.00220554  0.00263418 -0.0027679   0.0083447   0.0018528\n  0.00518835 -0.00279329 -0.00208305 -0.00124072  0.00609247  0.00190262\n  0.00851321 -0.00426651 -0.00421024 -0.00066578  0.00870842 -0.00653062\n -0.00640617  0.00649498 -0.00442916  0.00213549 -0.00708909 -0.00422932\n  0.00595916 -0.00876917 -0.00636945 -0.00719409  0.00163048 -0.00723266\n -0.0057939   0.00397894 -0.0087928   0.00373608  0.00448703  0.0029556\n -0.00303943 -0.0060539   0.00586317 -0.00761624  0.00456922 -0.00184545\n  0.00889112  0.00771731  0.00943092  0.00307518 -0.00291677 -0.00240685]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 54, "linear_w": 0.66, "X_train": "[0.55532068 0.01154693 0.28828264 0.36673387 0.10883513 0.72621381]", "Y_train": "[0.45152727 0.09806767 0.14746042 0.22082558 0.12152491 0.52132265]", "X_test": "[0.81496524 0.81769509 0.88766997 0.68806288 0.57941593 0.74168361\n 0.02127376 0.22008065 0.56836704 0.77510043 0.96951087 0.1529502\n 0.80664318 0.46957349 0.66508892 0.27226975 0.67153626 0.07640118\n 0.67949335 0.92078468]", "Y_test": "[0.81496524 0.81769509 0.88766997 0.68806288 0.57941593 0.74168361\n 0.02127376 0.22008065 0.56836704 0.77510043 0.96951087 0.1529502\n 0.80664318 0.46957349 0.66508892 0.27226975 0.67153626 0.07640118\n 0.67949335 0.92078468]"}