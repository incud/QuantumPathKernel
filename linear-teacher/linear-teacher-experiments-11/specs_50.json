{"initial_params": "[ 0.00943838  0.00111003  0.00730002  0.00541734  0.00181592  0.00457976\n -0.00926351  0.0099003   0.00968436 -0.00837033 -0.00450682 -0.00413113\n  0.0064429   0.00789094  0.00818943 -0.00864281 -0.00383088 -0.00213453\n  0.00985591  0.00250303 -0.0046826   0.00538155 -0.00680239  0.00206901\n -0.00714394 -0.00401707 -0.00747185 -0.0092359   0.00365737  0.00145538\n -0.00583975  0.00236887 -0.00253269  0.00210064 -0.00221617  0.00915293\n  0.00054926  0.00240075  0.00105418 -0.00814294  0.00840778 -0.00872305\n -0.00863314  0.00303117  0.00516446  0.00213099 -0.00285219  0.0031554\n  0.00999583  0.00109806]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 50, "linear_w": 0.66, "X_train": "[0.30627427 0.46182858 0.44885746 0.61548482 0.36287365 0.81308279]", "Y_train": "[0.29850062 0.32650798 0.30311884 0.34541046 0.18641584 0.60426088]", "X_test": "[0.18151373 0.88348167 0.88558545 0.38353461 0.43712123 0.29790387\n 0.43702931 0.03932366 0.58280177 0.32205646 0.72440069 0.46365928\n 0.77255304 0.75293096 0.97204779 0.1671859  0.21656859 0.1007973\n 0.93773487 0.03376731]", "Y_test": "[0.18151373 0.88348167 0.88558545 0.38353461 0.43712123 0.29790387\n 0.43702931 0.03932366 0.58280177 0.32205646 0.72440069 0.46365928\n 0.77255304 0.75293096 0.97204779 0.1671859  0.21656859 0.1007973\n 0.93773487 0.03376731]"}