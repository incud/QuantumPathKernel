{"initial_params": "[-0.00578429 -0.00885984  0.00359644 -0.00259544 -0.00411318  0.0031279\n  0.00732944 -0.00411689 -0.00014887 -0.00247974 -0.002781   -0.00813054\n -0.00804763  0.00324969 -0.00979845  0.00603486 -0.0085442  -0.00707431\n  0.0055768   0.00588704  0.0022813  -0.00738524  0.00211031  0.00733383\n  0.00266746 -0.00041571  0.00272055  0.00857867  0.00934042  0.00019114\n -0.00687542  0.00665379 -0.00512501 -0.00240541 -0.00964948  0.00710369\n  0.00041195 -0.00446276  0.00993558 -0.00867203 -0.00350893 -0.00627033\n  0.00222964  0.00253055  0.00290728 -0.00920157 -0.00268969  0.00143805\n -0.00917722  0.00100626  0.00058822  0.00580158 -0.00385966 -0.00274458\n -0.00908681 -0.0098753   0.003832    0.00670593  0.00148161]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 59, "linear_w": 0.66, "X_train": "[0.6052584  0.48174829 0.34641706 0.59959022 0.57123627 0.74068996]", "Y_train": "[0.44635786 0.30863998 0.17994289 0.38560388 0.42155631 0.58239743]", "X_test": "[0.27171575 0.2295922  0.80262718 0.88787089 0.19444867 0.14044875\n 0.82293933 0.0844055  0.35600216 0.67029129 0.47741888 0.16253404\n 0.26488248 0.17485178 0.11878208 0.86282045 0.81276856 0.28337392\n 0.39191503 0.28101609]", "Y_test": "[0.27171575 0.2295922  0.80262718 0.88787089 0.19444867 0.14044875\n 0.82293933 0.0844055  0.35600216 0.67029129 0.47741888 0.16253404\n 0.26488248 0.17485178 0.11878208 0.86282045 0.81276856 0.28337392\n 0.39191503 0.28101609]"}