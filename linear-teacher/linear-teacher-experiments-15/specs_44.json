{"initial_params": "[-0.00726639 -0.00315953  0.00891448  0.00323269 -0.00827373  0.00199458\n -0.00369349  0.00331034  0.0015045  -0.00967342 -0.00144514 -0.00212688\n -0.00335372 -0.00301532  0.00558567 -0.00277172  0.00426762  0.00585972\n  0.00509506 -0.00176586 -0.00213504  0.00765142  0.00417686  0.0060301\n  0.00124824 -0.00164912  0.00717378 -0.0002736  -0.00188638  0.00979815\n  0.00872685  0.00600869  0.00714085 -0.00627979 -0.00450427 -0.00701129\n -0.00194429  0.00758435  0.00645412  0.00947983  0.00229842  0.00735955\n  0.00269258  0.00901511]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 44, "linear_w": 0.66, "X_train": "[0.98627372 0.03353955 0.10037646 0.4497301  0.9213721  0.66416396]", "Y_train": "[0.68537923 0.12083786 0.16101739 0.28721315 0.59074385 0.51515955]", "X_test": "[0.87617847 0.64683112 0.94569686 0.77345053 0.00289108 0.84955936\n 0.21144605 0.7360917  0.13723811 0.6029092  0.4129935  0.92995721\n 0.40164179 0.0614137  0.31814986 0.2031072  0.03677238 0.50006863\n 0.41809888 0.13775881]", "Y_test": "[0.87617847 0.64683112 0.94569686 0.77345053 0.00289108 0.84955936\n 0.21144605 0.7360917  0.13723811 0.6029092  0.4129935  0.92995721\n 0.40164179 0.0614137  0.31814986 0.2031072  0.03677238 0.50006863\n 0.41809888 0.13775881]"}