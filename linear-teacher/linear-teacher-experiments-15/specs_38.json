{"initial_params": "[ 0.00529982 -0.00649137 -0.00999922 -0.00441334  0.0034175  -0.00265907\n  0.00485581 -0.00198105  0.00528547  0.00276367  0.00560581  0.00806806\n  0.00454534 -0.00432256 -0.00793343  0.00055898 -0.00129733 -0.00683834\n  0.00280887  0.00987387  0.0048344  -0.00152826 -0.00181267 -0.00616843\n  0.00980609 -0.00853187 -0.00293246  0.00739406  0.00303983  0.00179269\n -0.00403836  0.00649924 -0.00235538 -0.00732313 -0.00309732 -0.0039832\n  0.00076688  0.0073017 ]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 38, "linear_w": 0.66, "X_train": "[0.35455871 0.9321874  0.31377822 0.68122383 0.23128429 0.26113821]", "Y_train": "[0.31011816 0.57561795 0.26557761 0.4056766  0.17450428 0.09774895]", "X_test": "[0.53337968 0.28962255 0.1349608  0.03627617 0.75791945 0.38364278\n 0.87299604 0.81087384 0.24835295 0.75289502 0.6798306  0.38190271\n 0.22534474 0.12302426 0.28105981 0.47249843 0.3501677  0.41850218\n 0.80692758 0.56394773]", "Y_test": "[0.53337968 0.28962255 0.1349608  0.03627617 0.75791945 0.38364278\n 0.87299604 0.81087384 0.24835295 0.75289502 0.6798306  0.38190271\n 0.22534474 0.12302426 0.28105981 0.47249843 0.3501677  0.41850218\n 0.80692758 0.56394773]"}