{"initial_params": "[-0.00315781  0.00491199 -0.00321324  0.00855299  0.00350822 -0.00527755\n -0.00811898 -0.00895812  0.00650631  0.00406164  0.00942864  0.00739673\n -0.00500453  0.00804784  0.00729256 -0.00622777 -0.00942181 -0.00432618\n -0.00295563  0.0093754  -0.00521857  0.00101218 -0.00902671 -0.00971998\n  0.00201939 -0.00447455 -0.00587314 -0.00621094  0.00389005 -0.00737598\n  0.00768312  0.00013643 -0.00853694  0.00750512 -0.00581753 -0.00923527\n -0.00949343 -0.00300397  0.0060054   0.00584956  0.00017862  0.00204914\n  0.00383276 -0.0075473  -0.00044323 -0.00327098  0.00436971  0.00218524\n  0.00399997  0.00463959  0.00111209 -0.00587867  0.00588509 -0.00870559\n -0.00816881 -0.00867099  0.00226832  0.00429931]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 58, "linear_w": 0.66, "X_train": "[0.12306372 0.35962615 0.63215388 0.01723851 0.81137019 0.56770382]", "Y_train": "[ 0.0058599   0.33334698  0.46493482 -0.00220487  0.53147831  0.3196067 ]", "X_test": "[0.72765733 0.49822759 0.20735649 0.83807816 0.93418726 0.22870679\n 0.60767625 0.06369386 0.53637312 0.9640011  0.20652294 0.78477408\n 0.18662812 0.79659792 0.49681508 0.56613941 0.66529791 0.48146673\n 0.06510934 0.88516241]", "Y_test": "[0.72765733 0.49822759 0.20735649 0.83807816 0.93418726 0.22870679\n 0.60767625 0.06369386 0.53637312 0.9640011  0.20652294 0.78477408\n 0.18662812 0.79659792 0.49681508 0.56613941 0.66529791 0.48146673\n 0.06510934 0.88516241]"}