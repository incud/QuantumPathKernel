{"initial_params": "[-0.00710083  0.00640436  0.00536629 -0.0085338   0.00244963  0.0061047\n -0.00794121  0.00824006 -0.00964665 -0.00020916 -0.00663669  0.00044102\n -0.00490492 -0.00286259  0.00826692 -0.00848305 -0.00562002  0.00048323\n -0.00533659  0.00961262  0.00288876  0.00950922  0.00939059  0.00084333\n -0.00303556  0.00827354 -0.0007602   0.00035356 -0.00548635  0.00737402\n  0.00765939 -0.00775667  0.0004637   0.00651287 -0.00829877  0.00769535\n -0.00816139  0.00878473 -0.00463105  0.00820113  0.00111092 -0.00191655\n  0.00156561  0.00137989  0.00199137  0.00446969 -0.00442613  0.0096202\n -0.00338435 -0.00204128  0.00527494  0.00562914  0.00530065]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 53, "linear_w": 0.66, "X_train": "[0.44815716 0.43370073 0.94541629 0.99106897 0.85914737 0.4532024 ]", "Y_train": "[0.20815588 0.37626802 0.70452755 0.71636834 0.58910966 0.2324128 ]", "X_test": "[0.31689326 0.01140317 0.02761966 0.05203849 0.5129079  0.76832621\n 0.84177338 0.90346163 0.08349671 0.96192991 0.79697049 0.07780457\n 0.88915389 0.14828848 0.45877057 0.66810486 0.80235507 0.2614662\n 0.95139499 0.61333477]", "Y_test": "[0.31689326 0.01140317 0.02761966 0.05203849 0.5129079  0.76832621\n 0.84177338 0.90346163 0.08349671 0.96192991 0.79697049 0.07780457\n 0.88915389 0.14828848 0.45877057 0.66810486 0.80235507 0.2614662\n 0.95139499 0.61333477]"}