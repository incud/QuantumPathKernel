{"initial_params": "[-0.00762754  0.00245965 -0.00169398  0.00103014 -0.00568925  0.00712544\n -0.00896986 -0.00805356 -0.00902612 -0.00287861 -0.00737981  0.0046803\n -0.0056671  -0.0006199   0.00600103 -0.00430535 -0.00955778  0.00872462\n -0.00197383  0.0006699   0.00656408  0.0041341  -0.00311144  0.00719445\n  0.0043894  -0.00845164  0.00171135  0.00334835 -0.00178105  0.00207365\n  0.00429592 -0.00901548  0.00528063  0.00309822  0.00058979 -0.00039712\n -0.00997809  0.00532779 -0.00424123  0.0057047  -0.00378615]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 41, "linear_w": 0.66, "X_train": "[0.67299257 0.77214583 0.82463945 0.05587129 0.36598213 0.28509698]", "Y_train": "[0.50580609 0.51571892 0.47367611 0.11117565 0.31824473 0.16841567]", "X_test": "[0.08666509 0.3984212  0.60494783 0.05703932 0.05722184 0.40250945\n 0.92669113 0.64867645 0.34316338 0.6851905  0.55907758 0.74085534\n 0.66094385 0.73601446 0.90557774 0.88462631 0.06283057 0.54575452\n 0.48801322 0.15023778]", "Y_test": "[0.05719896 0.26295799 0.39926557 0.03764595 0.03776641 0.26565624\n 0.61161615 0.42812646 0.22648783 0.45222573 0.3689912  0.48896452\n 0.43622294 0.48576954 0.59768131 0.58385336 0.04146818 0.36019798\n 0.32208873 0.09915693]"}