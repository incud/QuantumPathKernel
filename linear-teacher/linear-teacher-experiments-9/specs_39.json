{"initial_params": "[-0.00726466 -0.00380245  0.00332648 -0.00170021 -0.00047952 -0.003405\n  0.00823606  0.00322521  0.00590115  0.00985333  0.00032284  0.00235539\n -0.00605529 -0.00511236  0.00240352 -0.00481635 -0.00481005  0.00444062\n  0.00885307 -0.00261676  0.00957265 -0.00486764 -0.00104674  0.00989963\n  0.00105051 -0.00630166  0.00026625 -0.00275588 -0.00338221 -0.00818779\n  0.00119922 -0.00194872  0.00183127 -0.00347405  0.00389946 -0.00311164\n -0.00725026 -0.00523611  0.00129443]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 39, "linear_w": 0.66, "X_train": "[0.83063443 0.94914095 0.3056931  0.84074742 0.74836071 0.32914454]", "Y_train": "[0.52663404 0.61893746 0.16823075 0.47482381 0.46309902 0.20425033]", "X_test": "[0.29780994 0.29906885 0.72734887 0.00958721 0.38351507 0.79477776\n 0.62873555 0.84203859 0.06119899 0.85749466 0.18672111 0.79633399\n 0.47438668 0.04258542 0.27764155 0.76671062 0.26973462 0.12184016\n 0.49869783 0.23451386]", "Y_test": "[0.19655456 0.19738544 0.48005025 0.00632756 0.25311995 0.52455332\n 0.41496546 0.55574547 0.04039133 0.56594648 0.12323593 0.52558043\n 0.31309521 0.02810638 0.18324342 0.50602901 0.17802485 0.08041451\n 0.32914057 0.15477915]"}