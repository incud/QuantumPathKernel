{"initial_params": "[ 0.00551702 -0.009746   -0.00078495 -0.00092706 -0.00290189 -0.00167113\n  0.00521157  0.00935948  0.00362069 -0.00166741 -0.0075871  -0.00639308\n  0.00527689 -0.00323218 -0.0074659  -0.00506303  0.00322847  0.00203406\n -0.00788882  0.00763755  0.00866747 -0.00256956  0.00945565  0.00156883\n -0.0028947  -0.00391475 -0.00508532 -0.00718934 -0.00080194 -0.00286834\n  0.00011774 -0.00417149  0.00844552  0.00015762 -0.00061706 -0.0094379\n  0.00940073 -0.0078138  -0.0080319   0.00114815  0.00554677  0.00518076\n -0.00910605  0.00105446 -0.00091929  0.00640987 -0.00715691 -0.00685448\n -0.00423082 -0.00058006 -0.00692898 -0.00759487 -0.0030247   0.00417935]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 54, "linear_w": 0.66, "X_train": "[0.2974623  0.37560673 0.49276782 0.55277089 0.78906869 0.99485366]", "Y_train": "[0.1436918  0.32957073 0.37267946 0.44722812 0.52069287 0.70207375]", "X_test": "[0.06950938 0.66527586 0.62057308 0.78848375 0.00740579 0.49611296\n 0.02143062 0.74990194 0.76927106 0.98993569 0.59926458 0.69343999\n 0.17447939 0.39680991 0.95106876 0.12602063 0.0372343  0.2510643\n 0.61102466 0.49445639]", "Y_test": "[0.04587619 0.43908207 0.40957823 0.52039928 0.00488782 0.32743455\n 0.01414421 0.49493528 0.5077189  0.65335756 0.39551462 0.45767039\n 0.1151564  0.26189454 0.62770538 0.08317362 0.02457464 0.16570244\n 0.40327628 0.32634122]"}