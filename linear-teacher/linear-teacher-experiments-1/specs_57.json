{"initial_params": "[ 0.00241504  0.00129835 -0.00470898  0.00873604  0.00519846 -0.00525761\n -0.00223308 -0.00451726 -0.00986454  0.0099725   0.00909727 -0.0096247\n  0.00460263  0.00380911 -0.00341984 -0.005123    0.00282796 -0.00446401\n  0.00318979 -0.00982926 -0.00445424  0.0089039  -0.00123608  0.00821233\n  0.00523718 -0.00503802  0.00387873 -0.00462668  0.0019375   0.00791732\n -0.00208524  0.00203362  0.00112886  0.00625462  0.00153366 -0.00089828\n -0.00151327  0.00354189 -0.00265068  0.00118961  0.00929044  0.00043592\n  0.00334978  0.00073646  0.00280186 -0.00984625  0.00390941 -0.0021806\n  0.00754507  0.00989382 -0.00944384  0.00147977 -0.00423518 -0.00436951\n -0.00576384 -0.00605307  0.00664741]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 57, "linear_w": 0.66, "X_train": "[0.55442448 0.10243307 0.29097    0.69371804 0.08135273 0.80862901]", "Y_train": "[ 0.32493391  0.07612575  0.27024898  0.46205315 -0.04139915  0.62313591]", "X_test": "[0.33182232 0.88853655 0.3546036  0.23736162 0.98328336 0.14598112\n 0.40330527 0.23867226 0.19597439 0.01030495 0.78495751 0.18372132\n 0.21791557 0.01613851 0.46564017 0.71266547 0.35455956 0.66158248\n 0.49708042 0.25774292]", "Y_test": "[0.21900273 0.58643412 0.23403838 0.15665867 0.64896702 0.09634754\n 0.26618148 0.15752369 0.1293431  0.00680127 0.51807196 0.12125607\n 0.14382428 0.01065142 0.30732251 0.47035921 0.23400931 0.43664444\n 0.32807308 0.17011033]"}