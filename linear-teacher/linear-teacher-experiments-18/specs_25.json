{"initial_params": "[ 2.66795786e-03 -1.10200243e-03 -4.19668600e-03  7.01352862e-05\n  7.02077656e-03 -2.92409307e-03 -4.13383708e-04  9.89981578e-03\n  6.79907250e-03 -2.76639079e-03  9.00750927e-03 -1.99664212e-03\n  2.03968674e-03 -4.96244687e-03 -4.10902385e-03 -2.09094298e-03\n  6.68264153e-03  9.03317275e-03 -6.50744030e-04  9.08745300e-04\n  5.09970390e-03 -4.55411598e-03  7.09741855e-03  8.16430370e-03\n -4.22296457e-03]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 25, "linear_w": 0.66, "X_train": "[0.05385814 0.42418506 0.81472089 0.6373421  0.66221627 0.36149481]", "Y_train": "[0.00145939 0.37555652 0.53426564 0.44817777 0.4537009  0.3330891 ]", "X_test": "[0.26161957 0.05551719 0.63676265 0.12134922 0.2449187  0.98019635\n 0.45192895 0.25297452 0.0304874  0.23926307 0.14767992 0.13490695\n 0.98875135 0.61192738 0.16719105 0.00759629 0.51245412 0.65462004\n 0.19397234 0.36675457]", "Y_test": "[0.17266892 0.03664135 0.42026335 0.08009049 0.16164634 0.64692959\n 0.29827311 0.16696318 0.02012168 0.15791363 0.09746875 0.08903859\n 0.65257589 0.40387207 0.11034609 0.00501355 0.33821972 0.43204923\n 0.12802174 0.24205802]"}