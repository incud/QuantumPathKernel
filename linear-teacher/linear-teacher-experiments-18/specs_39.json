{"initial_params": "[-0.00533024 -0.00399818 -0.00101949  0.00623519 -0.00767639  0.00283648\n -0.00611698  0.00826177 -0.00171838  0.00338369  0.00418081 -0.00646964\n  0.00148567 -0.00876126 -0.00588303 -0.00541345 -0.00693029 -0.00346723\n  0.00088739 -0.00399385  0.00388733  0.00405696 -0.00120066  0.00742968\n -0.00921651 -0.00346375  0.00862904 -0.00670474  0.00072854  0.00104266\n  0.00743528  0.00015162 -0.00700871 -0.00125953  0.00522361  0.00052052\n -0.00328176 -0.00071741 -0.00388445]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 39, "linear_w": 0.66, "X_train": "[0.45707653 0.61337512 0.59003174 0.25697199 0.58501798 0.45687951]", "Y_train": "[0.20726612 0.44841351 0.32632524 0.15988313 0.34228617 0.39360966]", "X_test": "[0.45191111 0.21509442 0.43097261 0.94320078 0.77559067 0.28095195\n 0.46181333 0.29836963 0.94895583 0.09939393 0.46428645 0.68963606\n 0.28471281 0.3855626  0.56551497 0.8932499  0.92166455 0.82079138\n 0.27228334 0.5916634 ]", "Y_test": "[0.29826133 0.14196232 0.28444192 0.62251251 0.51188984 0.18542829\n 0.3047968  0.19692396 0.62631085 0.06559999 0.30642906 0.4551598\n 0.18791045 0.25447132 0.37323988 0.58954493 0.6082986  0.54172231\n 0.179707   0.39049784]"}