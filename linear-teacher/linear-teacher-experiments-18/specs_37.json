{"initial_params": "[ 0.00170985  0.00535653 -0.00652298 -0.00965709  0.00492058  0.00258693\n -0.00512598  0.00918659 -0.00103788  0.00218272  0.00431223 -0.0079296\n -0.00040425 -0.00395543 -0.00935809 -0.00089325 -0.00490535  0.00746958\n -0.00980434  0.00196291  0.00508231  0.00935418  0.00955736 -0.00954242\n  0.00738625 -0.00668114  0.00383458  0.00801659  0.00304876 -0.00227547\n -0.00891038  0.00358739 -0.00749481 -0.00748854 -0.00119459  0.00375942\n  0.00015326]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 37, "linear_w": 0.66, "X_train": "[0.83121417 0.74011881 0.22391014 0.58781701 0.31403146 0.68644987]", "Y_train": "[0.45275588 0.48744448 0.13175072 0.44413348 0.30261523 0.42146447]", "X_test": "[0.20957723 0.96009894 0.00339836 0.92084705 0.76331772 0.61396425\n 0.64871058 0.40649529 0.46478459 0.10928164 0.71653983 0.32014046\n 0.02916773 0.93911356 0.18485217 0.82352343 0.68679182 0.15721888\n 0.38502301 0.75130121]", "Y_test": "[0.20957723 0.96009894 0.00339836 0.92084705 0.76331772 0.61396425\n 0.64871058 0.40649529 0.46478459 0.10928164 0.71653983 0.32014046\n 0.02916773 0.93911356 0.18485217 0.82352343 0.68679182 0.15721888\n 0.38502301 0.75130121]"}