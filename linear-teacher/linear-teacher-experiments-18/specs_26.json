{"initial_params": "[-5.30345078e-04 -1.21211598e-03 -5.85456106e-03  5.18392797e-03\n  3.83232018e-03 -9.27602426e-03  4.05538728e-03 -7.91075178e-03\n -7.45928199e-03 -9.61349632e-03  7.10813594e-05  9.70145953e-03\n -1.08886893e-03  7.04933424e-03  1.54500761e-03 -3.15436397e-03\n -3.43296162e-03 -9.05145894e-03 -7.07406625e-03  8.91333713e-03\n -1.49267732e-04 -8.93529779e-03 -7.55875373e-03 -8.97633543e-03\n  8.69595225e-03 -7.30017362e-03]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 26, "linear_w": 0.66, "X_train": "[0.77411838 0.0132316  0.57208861 0.00253563 0.17114812 0.03299379]", "Y_train": "[ 0.42493772  0.03723163  0.40919641 -0.07418184  0.17842075  0.07974758]", "X_test": "[0.9094075  0.84790921 0.602625   0.8734577  0.05945466 0.46889529\n 0.03015552 0.18045204 0.72646009 0.1255605  0.46773043 0.23587498\n 0.40674449 0.39638303 0.06406443 0.71148801 0.94043941 0.63679992\n 0.0677296  0.90113743]", "Y_test": "[0.60020895 0.55962008 0.3977325  0.57648208 0.03924008 0.30947089\n 0.01990264 0.11909835 0.47946366 0.08286993 0.30870208 0.15567749\n 0.26845136 0.2616128  0.04228252 0.46958209 0.62069001 0.42028795\n 0.04470154 0.5947507 ]"}