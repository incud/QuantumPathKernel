{"initial_params": "[ 0.00614191  0.003428    0.00859504  0.00087469 -0.00520065 -0.00233252\n -0.00573856 -0.0028415  -0.00327306 -0.00545093 -0.00946853  0.00165452\n -0.00692522 -0.00018275 -0.00695168 -0.00666224 -0.00848783  0.0058684\n  0.00743802  0.0081647   0.00762721  0.00192244  0.00745732 -0.00477322\n -0.00716528  0.00422283 -0.00569991  0.00704262  0.00489237 -0.00592019\n  0.0032702   0.00426607 -0.00935719  0.00438986 -0.00871366 -0.0039392\n  0.00890024  0.00276414  0.00112089 -0.00668689  0.00597622  0.00316709\n -0.00949525 -0.00291158  0.00582083  0.00840375  0.00364381 -0.00524272\n  0.00834748 -0.00056404  0.00303858  0.0069449   0.00381469 -0.00917984]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 54, "linear_w": 0.66, "X_train": "[0.34792794 0.01908206 0.05601051 0.87485601 0.26888062 0.13027604]", "Y_train": "[ 0.30405847  0.07440169 -0.01307309  0.50659277  0.22873017  0.07541996]", "X_test": "[0.98243982 0.94646263 0.56437503 0.92173793 0.60030136 0.42122047\n 0.73310874 0.00752192 0.34885594 0.72983034 0.91263289 0.51169004\n 0.23342204 0.58861069 0.38287271 0.87236167 0.90878082 0.37028249\n 0.04992109 0.70084665]", "Y_test": "[0.98243982 0.94646263 0.56437503 0.92173793 0.60030136 0.42122047\n 0.73310874 0.00752192 0.34885594 0.72983034 0.91263289 0.51169004\n 0.23342204 0.58861069 0.38287271 0.87236167 0.90878082 0.37028249\n 0.04992109 0.70084665]"}