{"initial_params": "[-0.00673762 -0.00719332  0.00074799 -0.00237319 -0.00707491  0.00968769\n -0.0050471   0.00187925 -0.00776174  0.00678109 -0.00601621 -0.00874182\n  0.00410688 -0.00736629 -0.00901077  0.00457966  0.00682917  0.00916142\n  0.00673994 -0.00269485  0.00483642 -0.00599553  0.00040394 -0.00221484\n  0.00454776  0.00756923 -0.00486052  0.00774545 -0.00902905  0.00727824\n -0.00296737  0.00977721  0.00966588  0.00802342  0.00180643 -0.00036475\n -0.00458883  0.00756856 -0.00208443 -0.00481283  0.007375   -0.00432506\n  0.0054995   0.00452807  0.00727523 -0.00818005 -0.0064902   0.00389183]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 48, "linear_w": 0.66, "X_train": "[0.92784887 0.09050896 0.03688475 0.09692267 0.48646883 0.03659769]", "Y_train": "[ 0.60309898  0.08884132 -0.05395908  0.13367273  0.34512749  0.11951545]", "X_test": "[0.59007811 0.49486602 0.40002483 0.98965759 0.0111476  0.62940687\n 0.36531068 0.85580261 0.23418605 0.1275328  0.57878569 0.56480389\n 0.70120132 0.49656926 0.56779501 0.53275959 0.96995345 0.89301696\n 0.0871573  0.54108384]", "Y_test": "[0.59007811 0.49486602 0.40002483 0.98965759 0.0111476  0.62940687\n 0.36531068 0.85580261 0.23418605 0.1275328  0.57878569 0.56480389\n 0.70120132 0.49656926 0.56779501 0.53275959 0.96995345 0.89301696\n 0.0871573  0.54108384]"}