{"initial_params": "[ 0.00785453  0.00387259  0.00681537 -0.00477505  0.00377844 -0.00541847\n -0.00538707 -0.00844115  0.00074348  0.00574528 -0.001549    0.00264078\n -0.00363757 -0.00211356 -0.00385893  0.00702988 -0.00448355 -0.00438548\n  0.00720171 -0.00958238  0.00360878  0.00014187  0.00788803 -0.00448446\n  0.00551929 -0.00861979  0.0041297   0.00441995 -0.00138868 -0.00458881\n -0.00692453  0.00856136  0.00424398 -0.00808176  0.0063199   0.0009271\n  0.00499322  0.00565095  0.0077998  -0.00846499 -0.00706328  0.00249482\n  0.00911452  0.0064822  -0.00697041 -0.00095056  0.00445049 -0.00351089\n  0.00818548 -0.00026941 -0.00353643 -0.00946715  0.00911322 -0.00310577\n -0.00855867  0.00179623  0.00613267  0.00278514 -0.00057854  0.002287  ]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 60, "linear_w": 0.66, "X_train": "[0.96681124 0.23556285 0.79799223 0.14246944 0.62572603 0.11147299]", "Y_train": "[0.63860946 0.12966855 0.54104283 0.09759429 0.41780369 0.10329108]", "X_test": "[0.98800999 0.16496622 0.06234763 0.63678863 0.58625273 0.01527693\n 0.92503    0.70356028 0.07172918 0.63109315 0.85930493 0.5830024\n 0.36217273 0.05544354 0.05283745 0.79405642 0.34411267 0.66117023\n 0.00328378 0.59234653]", "Y_test": "[0.65208659 0.10887771 0.04114944 0.4202805  0.3869268  0.01008277\n 0.6105198  0.46434978 0.04734126 0.41652148 0.56714125 0.38478158\n 0.239034   0.03659274 0.03487272 0.52407724 0.22711436 0.43637235\n 0.00216729 0.39094871]"}