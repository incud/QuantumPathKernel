{"initial_params": "[ 0.00645435  0.0044103  -0.0014828  -0.00852851  0.00298489  0.00063989\n  0.00572435 -0.0074815  -0.00900284 -0.00619079  0.00470442 -0.00782547\n -0.00764442 -0.00387915 -0.00502795 -0.00971871 -0.00508586 -0.00416676\n  0.00664251 -0.00345466  0.00853808  0.00549665 -0.00335241 -0.0031934\n  0.00153834  0.0073478  -0.0059412   0.00612638 -0.00763328 -0.00652752\n  0.00464783 -0.00748922 -0.00695623  0.00984527 -0.00023674 -0.00365571\n  0.00641874]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 37, "linear_w": 0.66, "X_train": "[0.43679518 0.03540541 0.13309501 0.72899311 0.08780364 0.26851337]", "Y_train": "[0.28748747 0.00116237 0.00412286 0.42986746 0.03287787 0.12546249]", "X_test": "[0.62254485 0.74115394 0.04025662 0.14818835 0.35591041 0.98247444\n 0.7908857  0.32080745 0.29267116 0.12825299 0.65148904 0.6448565\n 0.08736453 0.3084608  0.38191217 0.39776849 0.65439235 0.66544341\n 0.56212105 0.65802589]", "Y_test": "[0.4108796  0.4891616  0.02656937 0.09780431 0.23490087 0.64843313\n 0.52198456 0.21173292 0.19316297 0.08464697 0.42998277 0.42560529\n 0.05766059 0.20358413 0.25206203 0.2625272  0.43189895 0.43919265\n 0.37099989 0.43429709]"}