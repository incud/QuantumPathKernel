{"initial_params": "[ 0.00922932  0.00676387  0.00816598  0.00149745 -0.00173276 -0.00239169\n  0.00222257  0.00091432 -0.00476876  0.00226732  0.0032078  -0.00444832\n -0.00097183 -0.0077788   0.00021637  0.00233411 -0.00534704 -0.00958969\n  0.0066537   0.00295141 -0.0040795   0.00595304 -0.00887771  0.00973609\n  0.00069771 -0.00686736 -0.00608217 -0.00688742 -0.00623147  0.00272081\n  0.00843483  0.00476517 -0.00811598 -0.00424202  0.00463769  0.00212932\n -0.0041719   0.00891875]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 38, "linear_w": 0.66, "X_train": "[0.63113136 0.85969233 0.69579767 0.45188237 0.50956184 0.20183198]", "Y_train": "[0.51530906 0.48970683 0.5141735  0.29771107 0.33385347 0.19094818]", "X_test": "[0.29529152 0.6580749  0.66811602 0.19465001 0.14790873 0.83396388\n 0.29291795 0.96826811 0.95843722 0.98438331 0.28610769 0.58362666\n 0.81234622 0.76692631 0.64614777 0.07188708 0.38917211 0.73700928\n 0.6959565  0.15034288]", "Y_test": "[0.1948924  0.43432943 0.44095657 0.12846901 0.09761976 0.55041616\n 0.19332585 0.63905695 0.63256857 0.64969298 0.18883108 0.3851936\n 0.53614851 0.50617136 0.42645753 0.04744547 0.25685359 0.48642612\n 0.45933129 0.0992263 ]"}