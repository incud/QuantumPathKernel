{"initial_params": "[-7.49740993e-03  9.15378611e-03  9.46627053e-03 -7.39120041e-03\n -3.82039645e-03 -4.65267121e-03  7.69166415e-03  1.55577339e-03\n -7.32835432e-04 -5.28953431e-03  6.81226250e-03  6.09428801e-03\n -1.89063055e-03 -9.13492300e-03 -2.04601836e-03  5.72786811e-03\n -9.46343156e-03 -6.15529909e-03  5.03080366e-03 -2.64851109e-03\n  9.43025214e-05 -6.82113366e-03 -5.14795089e-03  7.17230413e-03\n  7.93443876e-03]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 25, "linear_w": 0.66, "X_train": "[0.50701414 0.19995341 0.51502065 0.22893752 0.48897581 0.33991809]", "Y_train": "[0.31677897 0.14908182 0.39419153 0.18312386 0.36957132 0.21068626]", "X_test": "[0.46675009 0.34475718 0.23230506 0.04853088 0.77858076 0.33675368\n 0.26434084 0.27243821 0.2552019  0.14302741 0.66350702 0.23504771\n 0.4729251  0.09785461 0.49233726 0.54072461 0.41690262 0.02834215\n 0.61356494 0.61027876]", "Y_test": "[0.30805506 0.22753974 0.15332134 0.03203038 0.5138633  0.22225743\n 0.17446495 0.17980922 0.16843325 0.09439809 0.43791463 0.15513149\n 0.31213057 0.06458404 0.32494259 0.35687824 0.27515573 0.01870582\n 0.40495286 0.40278398]"}