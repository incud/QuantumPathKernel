{"initial_params": "[-1.02804554e-05  8.54342536e-03  7.21541308e-03 -9.71165226e-03\n -8.02953317e-04 -3.76635660e-03 -4.80910474e-03  2.00145929e-03\n -3.98567397e-03 -2.10569442e-03 -7.44730021e-03  1.81835016e-03\n  9.26142305e-03 -7.49820703e-04  3.93835411e-04 -7.91585711e-03\n -5.35512667e-03  2.43379262e-03 -5.92993548e-03 -6.68208763e-03\n -8.53330739e-03  4.04678004e-03  8.48639275e-03  7.26423649e-03]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 24, "linear_w": 0.66, "X_train": "[0.9203166  0.72638531 0.30106516 0.96702593 0.23493633 0.56469853]", "Y_train": "[0.6375036  0.38484862 0.22568385 0.69410696 0.20705886 0.34038239]", "X_test": "[0.36043532 0.93604625 0.03090237 0.46428039 0.5321007  0.08812977\n 0.60693296 0.5597193  0.94607507 0.48779602 0.79132245 0.43505478\n 0.93450473 0.308402   0.06451073 0.28738973 0.37147889 0.88699893\n 0.72533065 0.85761159]", "Y_test": "[0.36043532 0.93604625 0.03090237 0.46428039 0.5321007  0.08812977\n 0.60693296 0.5597193  0.94607507 0.48779602 0.79132245 0.43505478\n 0.93450473 0.308402   0.06451073 0.28738973 0.37147889 0.88699893\n 0.72533065 0.85761159]"}