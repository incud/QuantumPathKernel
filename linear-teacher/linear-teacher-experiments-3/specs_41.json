{"initial_params": "[ 0.00080833 -0.00714942 -0.00609905  0.00368866  0.00272091  0.00860439\n -0.00719703  0.00725886 -0.00933146  0.00810881  0.00508508  0.00447799\n  0.00296039 -0.00771452  0.00401329 -0.00476263  0.00317594  0.00545089\n  0.0083993   0.00985298  0.00503808  0.00164416  0.00184813 -0.0094131\n  0.00022043 -0.00938755 -0.00881824  0.00833317 -0.00501935 -0.00884556\n  0.00147174  0.00010205  0.00434731  0.00858353 -0.00887695  0.00781972\n  0.00688855 -0.00033762  0.00271233  0.00147194  0.00990076]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 41, "linear_w": 0.66, "X_train": "[0.22983972 0.56845329 0.69041489 0.14609103 0.20929931 0.26939232]", "Y_train": "[0.22040703 0.38758675 0.50162166 0.12375579 0.08164529 0.27249175]", "X_test": "[0.57311152 0.82738568 0.84270435 0.66000807 0.92656112 0.58312652\n 0.2729727  0.44910777 0.60036279 0.67141639 0.40705021 0.28542864\n 0.79307496 0.65355643 0.89801584 0.85081712 0.26936411 0.34206054\n 0.6861804  0.52295956]", "Y_test": "[0.57311152 0.82738568 0.84270435 0.66000807 0.92656112 0.58312652\n 0.2729727  0.44910777 0.60036279 0.67141639 0.40705021 0.28542864\n 0.79307496 0.65355643 0.89801584 0.85081712 0.26936411 0.34206054\n 0.6861804  0.52295956]"}