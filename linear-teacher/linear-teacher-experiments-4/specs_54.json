{"initial_params": "[ 0.0017529  -0.00681561 -0.00500344 -0.00533907  0.00038334  0.00064216\n  0.00867981 -0.0048092   0.0093267   0.00893098  0.00721873 -0.00762797\n  0.00612458 -0.00363956  0.00995781  0.00951484  0.00488642  0.00363123\n  0.0015734  -0.00972871 -0.0064528  -0.00278981 -0.00426526  0.00219059\n -0.00869008 -0.00638616 -0.00200829 -0.00691661  0.00619323 -0.00501177\n -0.0053193  -0.00893508  0.00013501  0.00941417 -0.00937547  0.00396907\n -0.00642349  0.00409679  0.00684022  0.00289976  0.0050857  -0.00527724\n  0.00855558  0.00292081 -0.00689087  0.00824333  0.008191   -0.00428713\n -0.00717745 -0.00995918  0.00289944  0.00185707 -0.0074464  -0.00386513]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 54, "linear_w": 0.66, "X_train": "[0.2307673  0.5022979  0.43556861 0.19508499 0.76778972 0.83829068]", "Y_train": "[0.16617058 0.42038651 0.27294498 0.15343942 0.56720979 0.6163546 ]", "X_test": "[0.61750767 0.22641288 0.84626841 0.00903257 0.72823733 0.89279886\n 0.8161859  0.01657929 0.59590828 0.70042444 0.44813767 0.01423484\n 0.4568473  0.43371076 0.22263199 0.21461376 0.68695921 0.45016515\n 0.94406901 0.5686862 ]", "Y_test": "[0.40755506 0.1494325  0.55853715 0.0059615  0.48063664 0.58924725\n 0.53868269 0.01094233 0.39329946 0.46228013 0.29577086 0.00939499\n 0.30151922 0.2862491  0.14693711 0.14164508 0.45339308 0.297109\n 0.62308555 0.37533289]"}