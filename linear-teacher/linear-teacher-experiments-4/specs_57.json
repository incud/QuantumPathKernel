{"initial_params": "[ 0.00285776 -0.00327701  0.00610012 -0.00023628 -0.00567245 -0.00678581\n  0.00484682  0.00996321 -0.00588883  0.00935051  0.00300238 -0.00095804\n -0.00537738 -0.00700361 -0.005447    0.00102557 -0.00539188 -0.00770657\n  0.0040351   0.00797216  0.00124115 -0.00467199 -0.00027149  0.00885819\n  0.00336869 -0.00796668  0.00022512  0.0031231   0.00269853  0.00013713\n  0.00823147  0.00309211  0.00049964 -0.00791086  0.00626834  0.00893337\n  0.00643375  0.00912564  0.00594943  0.00966779  0.00079638  0.00600278\n -0.00370302 -0.00166455  0.0060279  -0.00800721  0.0083129  -0.00111489\n  0.00343896  0.00786824  0.00740215  0.00598074  0.00618644  0.00077374\n  0.00787957  0.00288771  0.00712236]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 57, "linear_w": 0.66, "X_train": "[0.37383136 0.53499955 0.89776838 0.73045683 0.15817011 0.6919134 ]", "Y_train": "[0.2196817  0.32486685 0.6346574  0.5619829  0.1494838  0.52537623]", "X_test": "[0.83128617 0.9038356  0.75248471 0.13782563 0.83295639 0.71905737\n 0.49669707 0.84978252 0.53138665 0.78660683 0.75459659 0.19931362\n 0.89740151 0.79145173 0.5021891  0.22976325 0.91246981 0.11990795\n 0.5220008  0.51075368]", "Y_test": "[0.83128617 0.9038356  0.75248471 0.13782563 0.83295639 0.71905737\n 0.49669707 0.84978252 0.53138665 0.78660683 0.75459659 0.19931362\n 0.89740151 0.79145173 0.5021891  0.22976325 0.91246981 0.11990795\n 0.5220008  0.51075368]"}