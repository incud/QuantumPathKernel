{"initial_params": "[-9.76696913e-04  4.78027308e-03 -3.50956206e-03 -5.73151941e-03\n -2.22829446e-03  3.07528677e-03  9.04092288e-03 -2.09072360e-03\n  9.02022145e-04  2.19907909e-03  6.87581398e-03 -6.57156609e-03\n  1.66409342e-03  2.11729798e-03 -2.92959025e-03 -1.60970210e-03\n  9.99202312e-03 -7.66740129e-03  8.45939386e-03  2.28628688e-03\n  7.39862833e-04  1.47686931e-03  5.84239097e-05  3.67743423e-03\n -6.61145258e-03 -4.34214476e-03 -1.35171601e-03]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 27, "linear_w": 0.66, "X_train": "[0.19546523 0.60297342 0.44423323 0.82920701 0.75442826 0.32811214]", "Y_train": "[0.10858654 0.42577908 0.29521957 0.55143255 0.47131371 0.16276799]", "X_test": "[0.85588591 0.61495568 0.26741615 0.59611425 0.12709468 0.97966442\n 0.03382373 0.22174467 0.83901512 0.8830399  0.38520536 0.95801678\n 0.32066523 0.89557359 0.49466005 0.64465602 0.2898434  0.35102879\n 0.2529066  0.95309692]", "Y_test": "[0.5648847  0.40587075 0.17649466 0.39343541 0.08388249 0.64657852\n 0.02232366 0.14635148 0.55374998 0.58280633 0.25423554 0.63229107\n 0.21163905 0.59107857 0.32647563 0.42547297 0.19129664 0.231679\n 0.16691836 0.62904397]"}