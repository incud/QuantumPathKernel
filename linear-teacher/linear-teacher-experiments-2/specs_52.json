{"initial_params": "[ 0.00150654  0.00958239 -0.00076284  0.00045913  0.0082939   0.00845363\n -0.00819768 -0.00792286  0.00787853  0.00858213 -0.00167938 -0.00510208\n  0.00299388 -0.00514339  0.00476426  0.00203031  0.0065786  -0.00185999\n  0.00453584  0.00208855  0.00361471  0.00290013  0.00916303 -0.00142575\n -0.00837286  0.00974993  0.0012303   0.00628091 -0.00659216  0.00050197\n  0.00583175 -0.00900431 -0.0060843  -0.0016641  -0.00947947  0.0024505\n -0.00357877 -0.00010597  0.00814401 -0.00971288 -0.00889962 -0.00385441\n -0.00814575 -0.00750276  0.00169351  0.00328807  0.0024426  -0.00624054\n -0.00371782 -0.0048975   0.00978625 -0.00116946]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 52, "linear_w": 0.66, "X_train": "[0.86533862 0.10327449 0.96319893 0.01427238 0.94159345 0.40087087]", "Y_train": "[ 0.63309823  0.01910947  0.58585767 -0.028004    0.62637483  0.33162235]", "X_test": "[0.48782238 0.07274347 0.48166468 0.49956233 0.50942813 0.61055302\n 0.44247377 0.86079142 0.05570087 0.62033175 0.0859548  0.22761744\n 0.68941612 0.22082921 0.48565451 0.39910734 0.88670478 0.66776402\n 0.59582905 0.87878396]", "Y_test": "[0.48782238 0.07274347 0.48166468 0.49956233 0.50942813 0.61055302\n 0.44247377 0.86079142 0.05570087 0.62033175 0.0859548  0.22761744\n 0.68941612 0.22082921 0.48565451 0.39910734 0.88670478 0.66776402\n 0.59582905 0.87878396]"}