{"initial_params": "[-0.00269129 -0.00274181 -0.00696552 -0.00487931 -0.00228615 -0.00090932\n  0.00301474  0.0088644   0.00053341  0.00699175  0.000144   -0.00131429\n -0.00924168  0.0019918   0.00337526 -0.0029309  -0.00154833 -0.00120316\n -0.00529768  0.00512086 -0.00087776  0.00301901  0.00269109 -0.00203999\n  0.00058319  0.00161125 -0.00658018 -0.00654841 -0.00898266 -0.00268542\n -0.00825719  0.00566968 -0.00463374 -0.00357107 -0.00565933  0.00906418\n -0.00034275]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 37, "linear_w": 0.66, "X_train": "[0.07388626 0.54253603 0.81714215 0.09764111 0.83288512 0.04417573]", "Y_train": "[ 0.02948316  0.40832448  0.53726786  0.03988631  0.53678006 -0.06102787]", "X_test": "[0.5895313  0.2883294  0.76224891 0.6074154  0.43319531 0.82116522\n 0.79811661 0.02543917 0.52309416 0.52883435 0.40207278 0.76733461\n 0.76307311 0.73584003 0.19820923 0.52771875 0.36346081 0.40200188\n 0.47725635 0.27456946]", "Y_test": "[0.38909066 0.1902974  0.50308428 0.40089416 0.2859089  0.54196905\n 0.52675696 0.01678985 0.34524215 0.34903067 0.26536803 0.50644084\n 0.50362825 0.48565442 0.13081809 0.34829438 0.23988413 0.26532124\n 0.31498919 0.18121584]"}