{"initial_params": "[-0.00462668  0.00044322 -0.00578274  0.00851289 -0.00668369  0.00205642\n  0.00802056  0.00677683  0.00530771  0.00832771  0.00891994  0.00591835\n  0.00553556  0.00496286  0.00152573  0.00314321  0.00072843  0.00427356\n  0.00792665  0.00556447  0.00421403 -0.00233723 -0.00496082  0.00586415\n  0.00739284 -0.00589247  0.00176228  0.00288058  0.0037401  -0.00585156\n  0.00133243  0.00691633 -0.00150586 -0.00893816  0.00731514  0.0045747\n  0.00829345  0.0063988   0.0009554   0.00930529]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 40, "linear_w": 0.66, "X_train": "[0.96559053 0.85989896 0.51942422 0.87665812 0.66235227 0.27972477]", "Y_train": "[0.55293463 0.56378151 0.39506167 0.49283332 0.37707034 0.24677293]", "X_test": "[0.04150642 0.4346135  0.27583804 0.1331207  0.86886821 0.42303193\n 0.46965961 0.86771985 0.09967209 0.19709477 0.46577031 0.96066463\n 0.37970676 0.45710257 0.16361889 0.42904972 0.03677395 0.80490583\n 0.20475759 0.45390922]", "Y_test": "[0.04150642 0.4346135  0.27583804 0.1331207  0.86886821 0.42303193\n 0.46965961 0.86771985 0.09967209 0.19709477 0.46577031 0.96066463\n 0.37970676 0.45710257 0.16361889 0.42904972 0.03677395 0.80490583\n 0.20475759 0.45390922]"}