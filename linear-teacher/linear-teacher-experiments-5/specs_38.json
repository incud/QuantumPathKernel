{"initial_params": "[-0.00951571  0.0057931   0.00969713 -0.00507357  0.00271643  0.00698233\n  0.00718832 -0.00809624 -0.00351498 -0.00536366  0.00053895 -0.00266655\n  0.00979779  0.00638372  0.00198656  0.00473352 -0.0073795   0.00467458\n -0.00841662 -0.00783    -0.00386182 -0.00609236 -0.00094949 -0.00852655\n -0.00896918  0.00649938  0.00506199 -0.00271711 -0.00102556 -0.00840219\n -0.00757984 -0.00665214 -0.00309272 -0.00519512 -0.00223133  0.00940828\n  0.00910254  0.00812614]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 38, "linear_w": 0.66, "X_train": "[0.98572414 0.97463197 0.43719152 0.41774551 0.37488115 0.35568678]", "Y_train": "[0.73015525 0.64102144 0.36987009 0.27014419 0.22423965 0.3336004 ]", "X_test": "[0.26408428 0.05058277 0.32970188 0.98244847 0.05052897 0.82562352\n 0.76398371 0.31881049 0.61340564 0.16596432 0.78028942 0.31280512\n 0.27963951 0.02079423 0.07941182 0.65751214 0.80701162 0.57640051\n 0.66408166 0.73227809]", "Y_test": "[0.17429562 0.03338463 0.21760324 0.64841599 0.03334912 0.54491152\n 0.50422925 0.21041492 0.40484772 0.10953645 0.51499102 0.20645138\n 0.18456208 0.01372419 0.0524118  0.43395801 0.53262767 0.38042434\n 0.4382939  0.48330354]"}