{"initial_params": "[ 8.03365931e-03  3.38023207e-03 -7.37555342e-04  5.27667566e-03\n -8.65090213e-03 -7.73118976e-03 -5.95229580e-05 -3.10689684e-03\n -9.02253020e-03  2.41536869e-03  9.91872501e-03 -9.81792127e-03\n  1.17934707e-03  6.03766527e-03 -1.65501585e-03 -3.73766881e-03\n  2.31121361e-03  2.70639796e-03 -4.84225124e-03 -4.72431798e-04\n  1.59336865e-03 -5.08613280e-03 -7.05264869e-03  5.08069684e-03\n -7.40485673e-03  3.95934883e-03  8.82284380e-03  9.25499464e-03\n -7.45612320e-03 -2.54625481e-05 -4.34657991e-03 -5.81348806e-03\n  9.05316302e-03 -8.50458038e-03 -3.28278648e-03 -4.09123175e-04\n  2.80551844e-03  4.93497248e-03  4.33079550e-03  8.40978889e-03\n  8.33133343e-03 -9.82770600e-03 -8.96815413e-03 -1.52192395e-03\n  9.34715775e-03 -9.35773761e-03 -4.53688367e-03 -9.24581365e-03\n  3.88339581e-03 -6.10074395e-03 -9.71501965e-03  3.59428204e-03\n -3.98984294e-04 -6.99650267e-04 -3.00581187e-04  1.41135817e-03\n -3.63126161e-03  7.17156541e-03]", "optimizer": "<class 'pennylane.optimize.adam.AdamOptimizer'>", "epochs": 1000, "layers": 58, "linear_w": 0.66, "X_train": "[0.76750378 0.49468455 0.50209998 0.23254109 0.96757234 0.73012076]", "Y_train": "[0.54689879 0.24248899 0.40186691 0.09891993 0.71865094 0.46842748]", "X_test": "[0.98175361 0.29181443 0.08806959 0.54103934 0.72201221 0.66731215\n 0.05469158 0.28796579 0.6948341  0.15667742 0.96213268 0.75505616\n 0.65592587 0.05212646 0.94635851 0.95134518 0.5595029  0.28572913\n 0.7713581  0.65070237]", "Y_test": "[0.64795738 0.19259752 0.05812593 0.35708596 0.47652806 0.44042602\n 0.03609644 0.19005742 0.45859051 0.1034071  0.63500757 0.49833707\n 0.43291107 0.03440346 0.62459662 0.62788782 0.36927191 0.18858123\n 0.50909635 0.42946356]"}