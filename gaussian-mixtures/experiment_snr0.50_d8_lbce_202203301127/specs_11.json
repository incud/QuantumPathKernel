{"initial_params": "[-1.1331837  -0.24230821  2.1392012   1.0281725   0.8543662  -0.29114667\n -0.35867828  0.05679347 -3.5417423   2.8420665   1.3032364   0.10463343\n  1.3919156   0.80001277 -0.61935216  0.4503983  -0.05855118 -1.0299821\n  0.02165079 -0.5511222   0.08572244 -2.1268904 ]", "optimizer": "optax.adam(learning_rate=0.1)", "epochs": 1000, "n_params": 22, "circuit": "create_rzz_rx_qnn", "seed": 20220330194613, "X": "[[ 0.25399832  0.65703979  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.82587837 -0.17097531  0.          0.          0.          0.\n   0.          0.        ]\n [-0.12997214 -0.91717513  0.          0.          0.          0.\n   0.          0.        ]\n [-0.44431072  0.05951162  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.22811003  0.21403413  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.84516192 -0.0906775   0.          0.          0.          0.\n   0.          0.        ]\n [-0.74565601 -0.19454666  0.          0.          0.          0.\n   0.          0.        ]\n [-0.7218078   0.60670534  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.8841685   0.15331653  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.7462319  -0.30039433  0.          0.          0.          0.\n   0.          0.        ]\n [-0.13368328 -0.6729386   0.          0.          0.          0.\n   0.          0.        ]\n [-0.46493737  0.89967988  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.95057344  0.91753739  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.66187636 -0.16236533  0.          0.          0.          0.\n   0.          0.        ]\n [-0.12058128 -0.91177769  0.          0.          0.          0.\n   0.          0.        ]\n [-0.24106371  0.86985557  0.          0.          0.          0.\n   0.          0.        ]]", "Y": "[ 1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.]", "layers": 11, "D": 8, "snr": 0.5, "N": 16, "loss": "bce", "MAX_LAYERS": 20, "MAX_EPOCHS": 1000}