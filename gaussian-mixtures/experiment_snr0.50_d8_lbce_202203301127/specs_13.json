{"initial_params": "[-1.7751464   2.4593334  -0.89380366 -0.07701745  0.508584    0.41674423\n  0.19047342  0.6551918  -0.14589544 -2.230059   -0.3254665   0.0900126\n -0.79911834 -1.6975106   1.2954478  -0.98451066 -0.7202462   0.78526264\n  0.02288908  0.3816898  -1.0686791   0.30526078  0.19378416 -0.17730117\n -1.8508496  -0.04497902]", "optimizer": "optax.adam(learning_rate=0.1)", "epochs": 1000, "n_params": 26, "circuit": "create_rzz_rx_qnn", "seed": 20220330234833, "X": "[[ 0.25399832  0.65703979  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.82587837 -0.17097531  0.          0.          0.          0.\n   0.          0.        ]\n [-0.12997214 -0.91717513  0.          0.          0.          0.\n   0.          0.        ]\n [-0.44431072  0.05951162  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.22811003  0.21403413  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.84516192 -0.0906775   0.          0.          0.          0.\n   0.          0.        ]\n [-0.74565601 -0.19454666  0.          0.          0.          0.\n   0.          0.        ]\n [-0.7218078   0.60670534  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.8841685   0.15331653  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.7462319  -0.30039433  0.          0.          0.          0.\n   0.          0.        ]\n [-0.13368328 -0.6729386   0.          0.          0.          0.\n   0.          0.        ]\n [-0.46493737  0.89967988  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.95057344  0.91753739  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.66187636 -0.16236533  0.          0.          0.          0.\n   0.          0.        ]\n [-0.12058128 -0.91177769  0.          0.          0.          0.\n   0.          0.        ]\n [-0.24106371  0.86985557  0.          0.          0.          0.\n   0.          0.        ]]", "Y": "[ 1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.]", "layers": 13, "D": 8, "snr": 0.5, "N": 16, "loss": "bce", "MAX_LAYERS": 20, "MAX_EPOCHS": 1000}