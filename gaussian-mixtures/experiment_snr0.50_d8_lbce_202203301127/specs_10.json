{"initial_params": "[ 0.26924255 -0.94525295  0.385344    0.10400249 -0.15763311 -0.57565105\n  0.2807661  -2.334224    0.70975083 -2.4866772  -2.019313   -0.38366053\n -1.2182504  -0.76293147 -0.5539727   0.09057336 -0.648883   -0.5913274\n -0.6841631   0.69323176]", "optimizer": "optax.adam(learning_rate=0.1)", "epochs": 1000, "n_params": 20, "circuit": "create_rzz_rx_qnn", "seed": 20220330181201, "X": "[[ 0.25399832  0.65703979  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.82587837 -0.17097531  0.          0.          0.          0.\n   0.          0.        ]\n [-0.12997214 -0.91717513  0.          0.          0.          0.\n   0.          0.        ]\n [-0.44431072  0.05951162  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.22811003  0.21403413  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.84516192 -0.0906775   0.          0.          0.          0.\n   0.          0.        ]\n [-0.74565601 -0.19454666  0.          0.          0.          0.\n   0.          0.        ]\n [-0.7218078   0.60670534  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.8841685   0.15331653  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.7462319  -0.30039433  0.          0.          0.          0.\n   0.          0.        ]\n [-0.13368328 -0.6729386   0.          0.          0.          0.\n   0.          0.        ]\n [-0.46493737  0.89967988  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.95057344  0.91753739  0.          0.          0.          0.\n   0.          0.        ]\n [ 0.66187636 -0.16236533  0.          0.          0.          0.\n   0.          0.        ]\n [-0.12058128 -0.91177769  0.          0.          0.          0.\n   0.          0.        ]\n [-0.24106371  0.86985557  0.          0.          0.          0.\n   0.          0.        ]]", "Y": "[ 1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.]", "layers": 10, "D": 8, "snr": 0.5, "N": 16, "loss": "bce", "MAX_LAYERS": 20, "MAX_EPOCHS": 1000}